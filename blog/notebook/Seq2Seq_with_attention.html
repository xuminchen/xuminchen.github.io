<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Sequence to Sequence with Attention | Simon&#39;s Blog</title>
    <meta name="generator" content="VuePress 1.5.4">
    <link rel="shoutcut icon" type="image/x-icon" href="logo.jpeg">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/github-markdown-css/2.2.1/github-markdown.css">
    <meta name="description" content="">
    <link rel="preload" href="/assets/css/0.styles.bbe6d313.css" as="style"><link rel="preload" href="/assets/js/app.15c63893.js" as="script"><link rel="preload" href="/assets/js/2.83a52e8a.js" as="script"><link rel="preload" href="/assets/js/8.e2ad90ae.js" as="script"><link rel="prefetch" href="/assets/js/10.273339ea.js"><link rel="prefetch" href="/assets/js/11.f34c48bf.js"><link rel="prefetch" href="/assets/js/12.acca6533.js"><link rel="prefetch" href="/assets/js/13.277cc9aa.js"><link rel="prefetch" href="/assets/js/14.dab476be.js"><link rel="prefetch" href="/assets/js/15.b0e7e4e6.js"><link rel="prefetch" href="/assets/js/16.3dc194be.js"><link rel="prefetch" href="/assets/js/17.72a2f9f4.js"><link rel="prefetch" href="/assets/js/18.adf1b62c.js"><link rel="prefetch" href="/assets/js/19.26404820.js"><link rel="prefetch" href="/assets/js/20.6e7aad67.js"><link rel="prefetch" href="/assets/js/21.74c7398f.js"><link rel="prefetch" href="/assets/js/22.3748e0d7.js"><link rel="prefetch" href="/assets/js/23.212a90bf.js"><link rel="prefetch" href="/assets/js/24.2ac39710.js"><link rel="prefetch" href="/assets/js/25.f02e60b9.js"><link rel="prefetch" href="/assets/js/26.e4d5dd86.js"><link rel="prefetch" href="/assets/js/27.0fd34753.js"><link rel="prefetch" href="/assets/js/28.700db19a.js"><link rel="prefetch" href="/assets/js/29.56b5f8da.js"><link rel="prefetch" href="/assets/js/3.ddb8398f.js"><link rel="prefetch" href="/assets/js/30.32ee25d2.js"><link rel="prefetch" href="/assets/js/31.d2e27490.js"><link rel="prefetch" href="/assets/js/32.7b2392e4.js"><link rel="prefetch" href="/assets/js/33.2e320e29.js"><link rel="prefetch" href="/assets/js/34.7b6d6140.js"><link rel="prefetch" href="/assets/js/35.fe23083b.js"><link rel="prefetch" href="/assets/js/36.5faf7922.js"><link rel="prefetch" href="/assets/js/37.e22ef41e.js"><link rel="prefetch" href="/assets/js/38.2b6f7ae4.js"><link rel="prefetch" href="/assets/js/39.8e26d55a.js"><link rel="prefetch" href="/assets/js/4.6545323a.js"><link rel="prefetch" href="/assets/js/40.67b90976.js"><link rel="prefetch" href="/assets/js/5.ed31ef13.js"><link rel="prefetch" href="/assets/js/6.bf0684a8.js"><link rel="prefetch" href="/assets/js/7.2dba22aa.js"><link rel="prefetch" href="/assets/js/9.b2ec3081.js">
    <link rel="stylesheet" href="/assets/css/0.styles.bbe6d313.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="logo.jpeg" alt="Simon's Blog" class="logo"> <span class="site-name can-hide">Simon's Blog</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/blog/notebook/" class="nav-link router-link-active">
  Blog
</a></div><div class="nav-item"><a href="/blog/competition/" class="nav-link">
  Competition
</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/blog/notebook/" class="nav-link router-link-active">
  Blog
</a></div><div class="nav-item"><a href="/blog/competition/" class="nav-link">
  Competition
</a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>Blog</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/blog/notebook/Introduction.html" class="sidebar-link">Introduction</a></li><li><a href="/blog/notebook/文本预处理.html" class="sidebar-link">文本预处理</a></li><li><a href="/blog/notebook/LR.html" class="sidebar-link">Logistic Regression</a></li><li><a href="/blog/notebook/Regularization.html" class="sidebar-link">Regularization</a></li><li><a href="/blog/notebook/SVM.html" class="sidebar-link">Support Vector Machine</a></li><li><a href="/blog/notebook/HMM.html" class="sidebar-link">Hidden Markov Model</a></li><li><a href="/blog/notebook/CRF.html" class="sidebar-link">Conditional Random Field</a></li><li><a href="/blog/notebook/decisiontree.html" class="sidebar-link">决策树系列</a></li><li><a href="/blog/notebook/Word2vec.html" class="sidebar-link">Word2vec</a></li><li><a href="/blog/notebook/Glove.html" class="sidebar-link">Glove</a></li><li><a href="/blog/notebook/RNN.html" class="sidebar-link">RNN</a></li><li><a href="/blog/notebook/LSTM.html" class="sidebar-link">LSTM</a></li><li><a href="/blog/notebook/GRU.html" class="sidebar-link">GRU</a></li><li><a href="/blog/notebook/Seq2Seq_with_attention.html" aria-current="page" class="active sidebar-link">Sequence to Sequence with Attention</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/blog/notebook/Seq2Seq_with_attention.html#introduction" class="sidebar-link">Introduction</a></li><li class="sidebar-sub-header"><a href="/blog/notebook/Seq2Seq_with_attention.html#attention" class="sidebar-link">Attention</a></li></ul></li><li><a href="/blog/notebook/Transformer.html" class="sidebar-link">Transformer</a></li><li><a href="/blog/notebook/TransformerXL.html" class="sidebar-link">TransformerXL</a></li><li><a href="/blog/notebook/BERT.html" class="sidebar-link">BERT</a></li><li><a href="/blog/notebook/BLEU.html" class="sidebar-link">BLEU</a></li><li><a href="/blog/notebook/HNSW.html" class="sidebar-link">HNSW</a></li><li><a href="/blog/notebook/study_material.html" class="sidebar-link">学习资料</a></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="sequence-to-sequence-with-attention"><a href="#sequence-to-sequence-with-attention" class="header-anchor">#</a> Sequence to Sequence with Attention</h1> <h2 id="introduction"><a href="#introduction" class="header-anchor">#</a> Introduction</h2> <p>一般来说，RNN和LSTM、GRU已经可以解决大量的NLP问题，但是在一些更专业的场景下，比如机器翻译，文本生成，单靠一个模型是无法有效地解决类似于语义理解的这些问题的，因此，提出了Seq2Seq的框架，由Encoder和Decoder模块一同完成这个任务。</p> <p>如下图所示，Seq2seq的结构非常简单，左边的是Encoder的部分，右边的是Decoder的部分，以机器翻译的场景为例，我们希望我们的模型能够理解语句的意思并完成中译英的翻译，因此，我们在Encoder中输入中文，最后在Decoder中输出英文。</p> <p><img src="/assets/img/seq2seq.5dcaabfe.png" alt="image-20200823155915855"></p> <p>整个过程并不难理解，两个模块其实内部都是RNN，在Encoder中，依次输入中文单词（字），输入完成后，输出最终的隐层向量，也就是<strong>语义向量</strong>，这个向量可以理解为模型对输入句子语义的理解，之后输入到Decoder中。Decoder接收到这个语义向量，在英语的空间里面，用英语将这个语义表达出来（一个个单词输出），这就是整个Seq2Seq。</p> <h2 id="attention"><a href="#attention" class="header-anchor">#</a> Attention</h2> <p>虽然Seq2Seq与传统的机器翻译相比，有了非常大的提升，但是依然存在了一些瓶颈，比如怎么知道两句话中的对应关系呢？中文输入：我喜欢你，英文输出：I love you，模型是怎么才能知道喜欢在这里对应的是love呢？这就不得不提Attention机制了。</p> <p>Attention机制如下图所示，输入的序列在经过Encoder后依然输出的是一个语义向量，但是这个语义向量不再和以前相同，这个语义向量中带有了单词在序列中占有的权重。具体的操作如下，序列中的token一一输入了Encoder之中，而输入后的每个hidden state都被存储起来，在Decoder中，首先<strong>起始符</strong>输入进模型，输出第一个单词hidden state，这个hidden state与Encoder中存储起来的所有hidden state进行点积（可以是其他相似度计算操作），之后对所有的计算结果做Softmax，得到Decoder要输出的这个单词在句中的权重，将这个权重与decoder的hidden state做一个加权平均，得到了属于当前单词的语义向量，并输入到后续模型中。</p> <p><img src="/assets/img/attention-1.b50c7b9f.png" alt="attention"></p> <blockquote><p>要注意，一开始传入Decoder中的hidden state，即在输入起始符的时候的隐层参数，和原始的seq2seq一样，是Encoder最后一层的输出。</p></blockquote> <p>通过了attention机制，加强了Encoder和Decoder两者的联系，使得模型在输出的时候，更知道句子输出的时候是哪个单词。后续的很多模型都用到了</p></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/blog/notebook/GRU.html" class="prev">
        GRU
      </a></span> <span class="next"><a href="/blog/notebook/Transformer.html">
        Transformer
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.15c63893.js" defer></script><script src="/assets/js/2.83a52e8a.js" defer></script><script src="/assets/js/8.e2ad90ae.js" defer></script>
  </body>
</html>
